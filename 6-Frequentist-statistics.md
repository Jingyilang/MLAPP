# 6-Frequentist-statistics

标签（空格分隔）： 未分类

---

## 6.1 引言
我们在5章中讨论的统计推断是贝叶斯统计学，可能有些惊讶的是，在某些人看来这是具有争议的，然而在一些非统计学的问题上应用贝叶斯规则是没有争议的。反对的原因是错误地区分了统计模型和其他未知参数的不同。
人们试图设计出避免treating parameters比如随机变量，和因此避免先验和贝叶斯规则的使用的统计推断，这些方法被叫做频率统计、经典统计或者正统统计(666，感觉这是贝叶斯统计和频率统计相爱相杀的故事233)。与基于后验分布不同的是，他们是基于样本分布的概念。这是这样的分布--当应用到多种多种数据集时，估计器从真实但是未知的分布中采样。，详细见6.2。正是这种在反复试验中的想法形成了采用频率方法对不确定性进行建模的基础。
相反的是，在贝叶斯方法中，我们仅仅对实际观测到的数据进行条件处理，没有反复试验的概念。这就允许贝叶斯定理计算一次性活动的概率，就如我们在2.1节中讨论的那样。可能更重要的是，贝叶斯方法避免了某些困扰着频率方法的悖论。然而，熟悉频率统计学派是很重要的，因为它在机器学习中被广泛地使用。
## 6.2 一个估计器的采样分布
在频率统计学派中，一个参数估计$\theta$<sup>^</sup>是数据集D上应用$\delta$计算而来的。参数被看做是固定的，而数据是随机的，这是和贝叶斯方法恰好相反的地方(按：贝叶斯引入先验就是认为参数也不是固定的，也是由某种分布产生的)。参数估计中的不确定性可以由计算估计器的样本分布来衡量。为了理解这一概念，想象从某些真实模型$p$(.|$\theta$<sup>*</sup>)中采样出不同的数据集$D$<sup>(s)</sup>，让$D$<sup>(s)</sup>={$x$<sub>$i$</sub>}<sup>$N$</sup> 公式不好打，略
## 6.3 频率决策理论
在频率或经典决策理论中，有损失函数和可能性，但是没有先验也因此没有后验或后验期望误差。因此不像贝叶斯那样自动的就有推导最优估计量的方法。取而代之的是，在频率方法中，我们可以自由的选择任何估计器或决策过程 $$[公式]$$
我们看到贝叶斯方法averages over $\theta$（这是未知的）和conditions on $D$(这是已知的)，而频率方法是averages over[] (因此忽略了已发现的数据)和 conditions on $\theta$<sup>~</sup>(这是未知的)
频率学派不仅定义起来的不自然的，它甚至都不能计算，因为$\theta$<sup>*</sup>是未知的。因此我们不能用频率论来比较不同估计器的风险。下面我们将讨论不同的解决方案。
### 6.3.1 贝叶斯风险
我们如何在不同的估计器之间选择？我们需要一些方法将$R$($\theta$<sup>*</sup>, $\delta$)转换成单数量的衡量，$R$($\delta$),这样就不需要依赖$\theta$<sup>*</sup>了。一个方法是在$\theta$<sup>*</sup>上加先验(按：不知道某个量，就假设其服从某个分布，高)，然后如下定义**贝叶斯风险**或称**积分风险**：
[公式]
一个**贝叶斯估计器**或者**贝叶斯决策规则**是要最小化如下的期望风险：
【公式】
要注意到积分风险也被称作preposterior risk，因此在看到数据之前，最小化这个对于实验设计是非常有用的。
我们将要证明一个非常重要的理论，该理论将贝叶斯和频率方法连接了起来。
$Theorem 6.3.1.$ 一个贝叶斯估计器可以由最小化每个x的后验期望风险而得到。 
证明略
因此我们看到在每个个案上采取最优动作（就如贝叶斯方法）平均起来整体就是最优的（一如频率方法）.换句话说，贝叶斯方法提供了一份很好的方法来达到频率学派的目标。事实上，我们可以再往下进一步：
$Theorem 6.3.2$ 每一个合理的决策理论都是贝叶斯决策理论加之一些，可能不合理的， 先验分布
该定理显示 **最小化频率风险的最好方法是贝叶斯!**,
### 6.3.2 极大极小风险
很显然，一些频率论者不喜欢贝叶斯风险因为它需要选择先验(尽管这只是对估计器的评估，并不一定是其结构的一部分)。替代方法如下，定义一个估计器的极大风险如
【公式】
极大极小规则是要极小化最大风险（在SVM里）:
[公式]
### 6.3.3 最合理的估计器
频率决策理论最基本的问题是他依赖于寻求真实的分布$p$($.$|$\theta$<sup>*</sup>)以便来衡量风险。但是，存在这样的情况：不管真实的分布的什么，某些估计器就是表现的比另一些估计器差。
## 6.4 估计器的理想性质
因为频率决策理论并不提供自动方法来选择最佳的估计器（**意思是贝叶斯提供了**）， 我们需要相处其他的启发式
方法来从中选择。 这一部分在中，我们讨论一些希望估计器具备的性质， 不幸的是，我们将看到我们不能同时得到这些
性质。

### 6.4.1 congsistant estimators
在当样本数量达到无穷大时， 估计器能够最终恢复真实参数 则称一个估计器的 consistant 的。当然只有在数据确实是从$/theta$
中产生的情况下，此概念才有意义。这是一个很有用的理论属性。
可以知道MLE是一个 consisitant estimator。 直观原因就是
### 6.4.2 Unbiased estimators
 说一个估计器是不偏置的意思是采样的分布在真实参数的中心。 比如说 MLE对高斯均值是不偏置的。但是对于
 高斯方差就是偏置的。
 尽管MLE有时是一个偏置的估计器， 但是也可以看到它是渐进不偏置。尽管不偏执听起来像是一个理想的属性
 但是并不总是这样。





